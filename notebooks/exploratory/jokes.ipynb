{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **0. Import Statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "import ast\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Load the Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading JSON data: 100%|██████████| 88832/88832 [00:54<00:00, 1632.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Processed JSON file path\n",
    "final_joke_dataset = r'..\\..\\data\\processed\\final_joke_dataset.json'\n",
    "\n",
    "# Open the file to count the number of lines (for progress tracking)\n",
    "with open(final_joke_dataset, 'r') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "# Load data from JSON file with progress bar\n",
    "data = []\n",
    "with open(final_joke_dataset, 'r') as f:\n",
    "    for line in tqdm(f, total=total_lines, desc=\"Loading JSON data\"):\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Prepare the Data for Modeling**\n",
    "\n",
    "**Encode the Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'category': 0\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in 'category'\n",
    "missing_categories = df['category'].isnull().sum()\n",
    "print(f\"Number of missing values in 'category': {missing_categories}\")\n",
    "\n",
    "# Drop rows where 'category' is NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "# Function to validate embeddings\n",
    "def is_valid_embedding(embedding):\n",
    "    return (\n",
    "        isinstance(embedding, list) and\n",
    "        len(embedding) == 1536 and\n",
    "        not any(pd.isnull(embedding)) and\n",
    "        not any(np.isnan(embedding))\n",
    "    )\n",
    "\n",
    "# Filter out invalid embeddings\n",
    "df = df[df['embedding'].apply(is_valid_embedding)]\n",
    "\n",
    "# Encode the categories to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# Calculate category counts\n",
    "category_counts = df['category_encoded'].value_counts()\n",
    "\n",
    "# Filter the DataFrame to keep only categories with more than one instance\n",
    "df_filtered = df[df['category_encoded'].isin(category_counts[category_counts > 1].index)]\n",
    "\n",
    "\n",
    "# Expand the embedding lists into separate columns\n",
    "embedding_cols = pd.DataFrame(df_filtered['embedding'].tolist())\n",
    "embedding_cols.columns = [f'embedding_{i}' for i in range(embedding_cols.shape[1])]\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_cleaned = df_filtered.drop(columns=['id', 'full_joke', 'embedding', 'category'])\n",
    "\n",
    "# Combine the expanded embeddings with the rest of the DataFrame\n",
    "df_final = pd.concat([embedding_cols, df_cleaned.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# Features (X) are the embeddings\n",
    "X = df_final.drop(columns=['category_encoded'])\n",
    "\n",
    "# Labels (y) are the category_encoded\n",
    "y = df_final['category_encoded']\n",
    "\n",
    "# Combine X and y to drop rows with any missing values\n",
    "data = pd.concat([X, y.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Separate X and y again\n",
    "X = data.drop(columns=['category_encoded'])\n",
    "y = data['category_encoded']\n",
    "\n",
    "# Perform train-test split with stratification\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_encoded\n",
      "371    16390\n",
      "122    15802\n",
      "381    11998\n",
      "165     5674\n",
      "340     4416\n",
      "       ...  \n",
      "434        1\n",
      "8          1\n",
      "48         1\n",
      "7          1\n",
      "214        1\n",
      "Name: count, Length: 476, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['category_encoded'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Set Up the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 1/10 [00:28<04:16, 28.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 10 trees in 28.47 seconds\n",
      "Estimated time remaining: 256.19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 2/10 [01:04<04:22, 32.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 20 trees in 64.27 seconds\n",
      "Estimated time remaining: 257.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  30%|███       | 3/10 [01:41<04:02, 34.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 30 trees in 101.27 seconds\n",
      "Estimated time remaining: 236.30 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  40%|████      | 4/10 [02:21<03:42, 37.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 40 trees in 141.87 seconds\n",
      "Estimated time remaining: 212.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  50%|█████     | 5/10 [03:05<03:16, 39.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 50 trees in 185.28 seconds\n",
      "Estimated time remaining: 185.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  60%|██████    | 6/10 [03:51<02:46, 41.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 60 trees in 231.57 seconds\n",
      "Estimated time remaining: 154.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  70%|███████   | 7/10 [04:34<02:06, 42.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 70 trees in 274.24 seconds\n",
      "Estimated time remaining: 117.53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  80%|████████  | 8/10 [05:14<01:22, 41.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 80 trees in 314.30 seconds\n",
      "Estimated time remaining: 78.58 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  90%|█████████ | 9/10 [05:57<00:42, 42.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 90 trees in 357.88 seconds\n",
      "Estimated time remaining: 39.76 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 10/10 [06:36<00:00, 39.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 100 trees in 396.86 seconds\n",
      "Estimated time remaining: 0.00 seconds\n",
      "Training completed in 396.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier with warm_start=True to allow incremental training\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=0,  # Start with 0 trees, we'll increment manually\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,       # Use all available cores\n",
    "    warm_start=True  # Allow incremental tree addition\n",
    ")\n",
    "\n",
    "n_total_trees = 100  # Total number of trees you want to train\n",
    "n_increment = 10     # Number of trees to add in each increment\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model incrementally and monitor progress\n",
    "for i in tqdm(range(0, n_total_trees, n_increment), desc=\"Training Progress\"):\n",
    "    rf_classifier.n_estimators += n_increment  # Add more trees in increments\n",
    "    rf_classifier.fit(X_train, y_train)        # Fit the new trees\n",
    "    \n",
    "    # Measure time so far\n",
    "    elapsed_time = time.time() - start_time\n",
    "    avg_time_per_tree = elapsed_time / (i + n_increment)\n",
    "    remaining_trees = n_total_trees - (i + n_increment)\n",
    "    remaining_time_estimate = avg_time_per_tree * remaining_trees\n",
    "    \n",
    "    print(f\"Trained {i + n_increment} trees in {elapsed_time:.2f} seconds\")\n",
    "    print(f\"Estimated time remaining: {remaining_time_estimate:.2f} seconds\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training completed in {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict on the Validation Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                   Adult       0.65      0.25      0.36       141\n",
      "            Adult (NSFW)       0.00      0.00      0.00         1\n",
      "             Adult humor       0.00      0.00      0.00         1\n",
      "                  Adult.       0.00      0.00      0.00         1\n",
      "            Adult/Erotic       0.00      0.00      0.00         2\n",
      "            Adult/Ethnic       0.00      0.00      0.00         3\n",
      "             Adult/Humor       0.00      0.00      0.00         1\n",
      "     Adult/Inappropriate       0.00      0.00      0.00         1\n",
      "              Adult/Puns       0.00      0.00      0.00         1\n",
      "            Adult/Sexual       0.00      0.00      0.00         1\n",
      "                     Age       0.00      0.00      0.00         1\n",
      "                 Alcohol       0.00      0.00      0.00         3\n",
      "                  Animal       0.79      0.51      0.62       344\n",
      "                     Bar       1.00      0.33      0.50         3\n",
      "                Bathroom       0.00      0.00      0.00         1\n",
      "                  Blonde       0.85      0.59      0.70       154\n",
      "                Celebity       0.00      0.00      0.00         1\n",
      "             Celebrities       0.00      0.00      0.00         1\n",
      "               Celebrity       0.88      0.24      0.38       124\n",
      "                     Dad       0.70      0.32      0.44       193\n",
      "              Dark Humor       0.53      0.82      0.64      1580\n",
      "             Dark Humor.       0.00      0.00      0.00         1\n",
      "          Dentist/Health       0.00      0.00      0.00         1\n",
      "                   Dirty       0.00      0.00      0.00         5\n",
      "         Dirty/Tasteless       0.00      0.00      0.00         1\n",
      "           Doctor/Health       0.84      0.53      0.65       256\n",
      "                    Drug       0.00      0.00      0.00         1\n",
      "             Educational       0.00      0.00      0.00         1\n",
      "                 Elderly       1.00      0.40      0.57         5\n",
      "                  Ethnic       0.86      0.54      0.67       567\n",
      "                  Family       0.53      0.16      0.25        50\n",
      "     Family/Relationship       0.00      0.00      0.00         1\n",
      "                    Food       0.76      0.20      0.31        81\n",
      "                  Gender       0.33      0.06      0.11        16\n",
      "           Gender/Ethnic       0.00      0.00      0.00         1\n",
      "     Gender/Relationship       0.00      0.00      0.00         1\n",
      "           Gender/Sexism       0.00      0.00      0.00         1\n",
      "            Generational       1.00      0.50      0.67         2\n",
      "                 Grammar       0.00      0.00      0.00         1\n",
      "                  Health       0.00      0.00      0.00         3\n",
      "           Health/Doctor       0.00      0.00      0.00         1\n",
      "              Historical       0.00      0.00      0.00         1\n",
      "                 Holiday       0.00      0.00      0.00         1\n",
      "                   Humor       0.00      0.00      0.00         1\n",
      "                  In-Law       0.71      0.29      0.42        17\n",
      "           Inappropriate       0.25      0.05      0.08        22\n",
      "             Insensitive       0.00      0.00      0.00         1\n",
      "                  Insult       0.82      0.19      0.31        47\n",
      "                Internet       0.00      0.00      0.00         1\n",
      "                     Kid       0.00      0.00      0.00         1\n",
      "                    Kids       0.62      0.23      0.34       122\n",
      "             Knock-Knock       1.00      0.07      0.12        15\n",
      "                   LGBT+       1.00      0.50      0.67         2\n",
      "                  LGBTQ+       0.00      0.00      0.00         1\n",
      "                  Lawyer       0.92      0.39      0.54        57\n",
      "                   Legal       0.00      0.00      0.00         1\n",
      "            Legal/Lawyer       0.00      0.00      0.00         1\n",
      "              Literature       0.00      0.00      0.00         1\n",
      "                Marriage       0.65      0.22      0.33       194\n",
      "                    Math       0.00      0.00      0.00         5\n",
      "        Math/Mathematics       0.00      0.00      0.00         1\n",
      "            Math/Science       0.00      0.00      0.00         1\n",
      "            Mathematical       0.00      0.00      0.00         1\n",
      "             Mathematics       0.00      0.00      0.00         2\n",
      "                 Medical       0.25      0.50      0.33         2\n",
      "          Medical/Doctor       0.00      0.00      0.00         1\n",
      "   Medical/Doctor/Health       0.00      0.00      0.00         2\n",
      "          Medical/Health       0.00      0.00      0.00         1\n",
      "                    Meta       0.00      0.00      0.00         3\n",
      "                Military       1.00      0.06      0.11        18\n",
      "                   Movie       0.00      0.00      0.00         1\n",
      "                   Music       1.00      0.20      0.33         5\n",
      "                    NSFW       0.00      0.00      0.00         2\n",
      "              One-Liners       0.62      0.21      0.31       442\n",
      "                  Parent       0.00      0.00      0.00         1\n",
      "               Parenting       0.00      0.00      0.00         3\n",
      "                Personal       0.00      0.00      0.00         1\n",
      "                  Pirate       0.00      0.00      0.00         1\n",
      "                  Police       0.00      0.00      0.00         2\n",
      "               Political       0.88      0.60      0.71       334\n",
      "                     Pun       0.00      0.00      0.00         8\n",
      "Punishments/Consequences       0.71      0.18      0.29        56\n",
      "                    Puns       0.50      0.84      0.63      1639\n",
      "                   Puns.       0.00      0.00      0.00         1\n",
      "            Relationship       0.64      0.80      0.71      1200\n",
      "           Relationship.       0.00      0.00      0.00         1\n",
      "                Religion       0.00      0.00      0.00         2\n",
      "               Religious       0.87      0.63      0.73       284\n",
      "                  School       0.77      0.34      0.47        96\n",
      "                  Sci-Fi       0.00      0.00      0.00         1\n",
      "                  Sci-fi       0.00      0.00      0.00         1\n",
      "                 Science       0.88      0.35      0.51       127\n",
      "                     Sex       0.00      0.00      0.00         2\n",
      "                  Sexist       0.00      0.00      0.00         1\n",
      "                  Sexual       0.00      0.00      0.00         2\n",
      "        Social/Political       0.00      0.00      0.00         1\n",
      "                  Sports       0.56      0.12      0.20        41\n",
      "               Star Wars       0.00      0.00      0.00         1\n",
      "                   Story       0.00      0.00      0.00         1\n",
      "                 Teacher       0.00      0.00      0.00         2\n",
      "                    Tech       0.84      0.27      0.41       205\n",
      "              Technology       0.00      0.00      0.00         1\n",
      "                  Travel       0.00      0.00      0.00         2\n",
      "                Wordplay       0.00      0.00      0.00         2\n",
      "             Work/Office       0.89      0.42      0.57       280\n",
      "                 Yo Mama       1.00      0.31      0.47        29\n",
      "\n",
      "               micro avg       0.61      0.61      0.61      8855\n",
      "               macro avg       0.27      0.12      0.16      8855\n",
      "            weighted avg       0.66      0.61      0.58      8855\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HBhenry\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HBhenry\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HBhenry\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Find the unique labels in y_val\n",
    "unique_labels = np.unique(y_val)\n",
    "\n",
    "# Filter target names to match the unique labels in y_val\n",
    "target_names = [label_encoder.inverse_transform([label])[0] for label in unique_labels]\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(\n",
    "    y_val, y_pred, labels=unique_labels, target_names=target_names\n",
    ")\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
